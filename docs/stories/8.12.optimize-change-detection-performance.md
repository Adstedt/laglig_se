# Story 8.12: Optimize Amendment Detection & Processing Performance

## Status

Draft (v2 — rewritten to align with actual sync-sfs-updates cron and event-driven architecture)

## Story

**As a** system operator,
**I want** the amendment detection pipeline to complete reliably within the Vercel 5-minute cron limit,
**so that** law changes are detected and processed consistently without timeouts or data loss.

## Context & Dependencies

**Builds on:**

- `sync-sfs-updates` cron — existing amendment detection pipeline at `app/api/cron/sync-sfs-updates/route.ts`
- `CronJobRun` model — existing execution tracking with `job_name`, `status`, `duration_ms`, `items_processed`, `items_failed`
- `AmendmentDocument` model — stores parsed amendment PDFs
- `SectionChange` model — per-section diffs
- `ChangeEvent` model — detected changes for notification pipeline
- `lib/email/cron-notifications.ts` — admin notification emails

**Key insight:** The actual architecture is **event-driven**, not polling. `sync-sfs-updates` queries the Riksdagen API for documents published since the last check (`systemdatum` comparison), NOT by fetching and hashing all laws. The v1 story proposed a fictional `detect-law-changes` cron with incremental hashing of 10,000 laws — this is entirely wrong.

**Actual detection flow:**

1. Query Riksdagen API: `dokument?sok=SFS&systemdatum>{lastCheck}&sort=systemdatum&sortorder=desc`
2. For each new document: extract SFS references, match to existing LegalDocuments
3. For amendments: fetch PDF → Claude PDF-direct parsing → SectionChange creation → ChangeEvent creation
4. Bottleneck: Claude LLM calls for PDF parsing (~10-15s each, sequential due to timeout budget)

**Real performance constraints:**

- Vercel Pro cron: `maxDuration = 300` (5 minutes hard limit)
- Current timeout protection: 30s buffer before maxDuration
- PDF parsing: ~10-15s per amendment (Claude API)
- Riksdagen API: reasonable rate, no known rate limiting for reads
- Typical daily volume: 0-5 new amendments (rarely >10)

## Acceptance Criteria

### Cron Reliability

1. `sync-sfs-updates` completes within 5-minute Vercel limit for typical daily volumes (0-10 amendments)
2. Timeout protection: gracefully stops LLM parsing when approaching time limit, resumes on next run
3. Unprocessed amendments (timeout or error) automatically picked up on next cron execution
4. No duplicate processing: check `AmendmentDocument.parse_status` before re-parsing

### Throughput Optimization

5. PDF parsing pipeline optimized: concurrent LLM calls where budget allows (max 2 parallel)
6. Riksdagen API pagination handled efficiently (single pass, not repeated queries)
7. Database writes batched where possible (bulk ChangeEvent creation)
8. Skip already-parsed amendments (`parse_status = COMPLETED`)

### Monitoring & Alerting

9. `CronJobRun` record created for every execution with: `items_processed`, `items_failed`, `duration_ms`, `metadata` (amendment count, timeout status)
10. Admin email (via `sendSfsSyncEmail`) on every run with stats
11. Alert email if cron fails or hits timeout 3+ times consecutively
12. Log structured output for Vercel function logs

### Backfill Capability

13. Manual trigger endpoint for admin to re-run sync with custom date range
14. Backfill mode: process amendments from a specific date range (for recovery after outages)
15. Rate limiting in backfill: max 15 amendments per run (to stay within timeout)

### Database Performance

16. Indexes on key query paths: `AmendmentDocument.parse_status`, `AmendmentDocument.created_at`, `ChangeEvent.detected_at`, `ChangeEvent.notification_sent`
17. Query optimization: use `select` to load only needed fields in hot paths
18. Connection pool management: appropriate pool size for cron context

### Admin Dashboard

19. Cron execution history visible in admin panel: last 30 runs with status, duration, items processed
20. Visual indicators: green (success), yellow (timeout/partial), red (failed)
21. Link to CronJobRun details with full metadata

## Tasks / Subtasks

- [ ] **Task 1: Optimize sync-sfs-updates pipeline** (AC: 1, 2, 3, 4, 5)
  - [ ] Review current timeout budget allocation
  - [ ] Add parallel LLM calls (max 2 concurrent) when budget allows
  - [ ] Ensure unprocessed amendments resume on next run
  - [ ] Add deduplication check before processing
- [ ] **Task 2: Improve Riksdagen API interaction** (AC: 6)
  - [ ] Optimize pagination handling
  - [ ] Cache `systemdatum` comparison date
  - [ ] Handle API errors gracefully
- [ ] **Task 3: Batch database writes** (AC: 7)
  - [ ] Batch ChangeEvent creation where possible
  - [ ] Use transactions for amendment + SectionChange + ChangeEvent creation
- [ ] **Task 4: CronJobRun tracking improvements** (AC: 9, 10, 11, 12)
  - [ ] Ensure CronJobRun created with comprehensive metadata
  - [ ] Add consecutive failure detection and escalation email
  - [ ] Structured logging for Vercel function logs
- [ ] **Task 5: Admin backfill endpoint** (AC: 13, 14, 15)
  - [ ] Server action for manual sync trigger with date range
  - [ ] Rate limiting: max 15 amendments per backfill run
  - [ ] Admin-only authorization check
- [ ] **Task 6: Database index review** (AC: 16, 17, 18)
  - [ ] Verify indexes exist on hot query paths
  - [ ] Add missing indexes via migration
  - [ ] Review connection pool settings for cron context
- [ ] **Task 7: Admin cron dashboard** (AC: 19, 20, 21)
  - [ ] Query CronJobRun records for sync-sfs-updates
  - [ ] Display in admin panel with status indicators
  - [ ] Link to detailed metadata view

## Dev Notes

### Source Tree (relevant files)

```
app/api/cron/sync-sfs-updates/route.ts       — Main detection cron (THE file to optimize)
app/api/cron/sync-sfs/route.ts               — New law sync (separate cron, not in scope)
lib/sfs/amendment-llm-prompt.ts              — Claude PDF parsing prompt
lib/sfs/amendment-to-legal-document.ts       — AmendmentDocument → LegalDocument bridge
lib/email/cron-notifications.ts              — sendSfsSyncEmail for admin alerts
prisma/schema.prisma                         — CronJobRun, AmendmentDocument, ChangeEvent
```

### Key Data Models

```
CronJobRun (existing)
  ├─ job_name: "sync-sfs-updates"
  ├─ status: RUNNING | SUCCESS | FAILED (JobRunStatus enum)
  ├─ started_at, completed_at, duration_ms
  ├─ items_processed, items_failed
  ├─ error_message, error_stack
  ├─ log_output
  ├─ triggered_by: "cron" | admin email
  └─ metadata: Json (amendment_count, timeout_hit, etc.)

AmendmentDocument
  ├─ parse_status: PENDING | PROCESSING | COMPLETED | FAILED (ParseStatus enum)
  └─ Used for deduplication: skip COMPLETED, retry FAILED/PENDING

Optimization flow:
  sync-sfs-updates GET
    → Query Riksdagen API (systemdatum > last check)
    → Filter to SFS documents with amendment references
    → For each amendment:
      → Check: AmendmentDocument exists with parse_status=COMPLETED? Skip.
      → Check: time remaining > 30s? Continue. Otherwise break.
      → Fetch PDF → Claude parse → SectionChange creation
      → Create ChangeEvent
    → Create CronJobRun record
    → Send admin email with stats
```

### Concurrent LLM Pattern

```typescript
// Current: sequential (safe, predictable budget)
for (const amendment of amendmentsToProcess) {
  if (elapsed > maxRuntime) break
  await processAmendment(amendment)
}

// Optimized: 2-parallel when budget allows
import pLimit from 'p-limit'
const limit = pLimit(2)
const remaining = amendmentsToProcess.slice(0, MAX_PER_RUN)
await Promise.allSettled(
  remaining.map(amendment => limit(async () => {
    if (Date.now() - startTime > maxRuntime) return
    await processAmendment(amendment)
  }))
)
```

### Index Verification

```sql
-- Verify these indexes exist (from schema.prisma @@index directives)
-- ChangeEvent: document_id, content_type, change_type, detected_at
-- AmendmentDocument: needs parse_status index (may need to add)
-- CronJobRun: [job_name, started_at DESC]
```

### Admin Backfill Pattern

```typescript
// Server action for manual backfill
'use server'
export async function triggerAmendmentBackfill(fromDate: string, toDate: string) {
  // Admin authorization check
  // Call sync-sfs-updates logic with custom date range
  // Rate limit: max 15 amendments
  // Return CronJobRun id for tracking
}
```

## Testing

**Test location:** `tests/unit/lib/cron/sync-sfs-updates-performance.test.ts`

**Test framework:** Vitest with `vi.mock()` for Prisma, Anthropic, fetch

**Unit tests:**
- Timeout protection stops processing before maxDuration
- Already-parsed amendments (parse_status=COMPLETED) are skipped
- Failed amendments are retried on next run
- CronJobRun record created with correct stats
- Admin email sent after each run
- Consecutive failure detection triggers escalation email
- Backfill respects max 15 amendment limit

**Integration tests:**
- Full cron cycle: Riksdagen query → amendment detection → PDF parse → ChangeEvent creation
- Timeout scenario: 10+ amendments, only processes within budget, records partial completion
- Admin dashboard displays CronJobRun history correctly

## Change Log

| Date       | Version | Description                                                    | Author     |
| ---------- | ------- | -------------------------------------------------------------- | ---------- |
| 2025-11-12 | 1.0     | Initial story creation (fictional detect-law-changes with polling/hashing) | Sarah (PO) |
| 2026-02-09 | 2.0     | Major rewrite: align with actual sync-sfs-updates event-driven architecture, remove fictional models (Law, LawChange, LawContentCache), focus on real bottlenecks (LLM throughput, timeout budget) | Sarah (PO) |

## Dev Agent Record

_To be populated by dev agent_

## QA Results

_To be populated by QA agent_
